{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7418691,"datasetId":4315922,"databundleVersionId":7510058}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================\n# SECTION 1: Import Libraries & Setup\n# ===============================\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset, Subset\nimport numpy as np\nimport random\nimport copy\n\n# Device configuration\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", DEVICE)\n\n# ===============================\n# DATASET PATH (Kaggle Notebook)\n# ===============================\nDATA_DIR = \"/kaggle/input/datasets/snikhilrao/crop-disease-detection-dataset/Plant Village Dataset\"\n\ntrain_dir = os.path.join(DATA_DIR, \"Train\")\nval_dir   = os.path.join(DATA_DIR, \"Val\")\ntest_dir  = os.path.join(DATA_DIR, \"Test\")\n\n# Safety check\nfor d in [train_dir, val_dir]:\n    if not os.path.exists(d):\n        raise FileNotFoundError(f\"Folder not found: {d}\")\n    print(f\"Folder {d} found. Classes: {os.listdir(d)}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-13T06:31:26.074446Z","iopub.execute_input":"2026-02-13T06:31:26.074753Z","iopub.status.idle":"2026-02-13T06:31:26.083455Z","shell.execute_reply.started":"2026-02-13T06:31:26.074728Z","shell.execute_reply":"2026-02-13T06:31:26.082834Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nFolder /kaggle/input/datasets/snikhilrao/crop-disease-detection-dataset/Plant Village Dataset/Train found. Classes: ['Grape - Healthy', 'Potato - Early Blight', 'Bell Pepper - Healthy', 'Potato - Late Blight', 'Corn (Maize) - Cercospora Leaf Spot', 'Tomato - Septoria Leaf Spot', 'Bell Pepper - Bacterial Spot', 'Cherry - Powdery Mildew', 'Apple - Healthy', 'Tomato - Late Blight', 'Tomato - Healthy', 'Tomato - Early Blight', 'Grape - Black Rot', 'Potato - Healthy', 'Corn (Maize) - Northern Leaf Blight', 'Strawberry - Leaf Scorch', 'Tomato - Bacterial Spot', 'Peach - Bacterial Spot', 'Corn (Maize) - Common Rust', 'Strawberry - Healthy', 'Cherry - Healthy', 'Grape - Esca (Black Measles)', 'Apple - Cedar Apple Rust', 'Tomato - Yellow Leaf Curl Virus', 'Apple - Apple Scab', 'Apple - Black Rot', 'Corn (Maize) - Healthy', 'Peach - Healthy', 'Grape - Leaf Blight']\nFolder /kaggle/input/datasets/snikhilrao/crop-disease-detection-dataset/Plant Village Dataset/Val found. Classes: ['Grape - Healthy', 'Potato - Early Blight', 'Bell Pepper - Healthy', 'Potato - Late Blight', 'Corn (Maize) - Cercospora Leaf Spot', 'Tomato - Septoria Leaf Spot', 'Bell Pepper - Bacterial Spot', 'Cherry - Powdery Mildew', 'Apple - Healthy', 'Tomato - Late Blight', 'Tomato - Healthy', 'Tomato - Early Blight', 'Grape - Black Rot', 'Potato - Healthy', 'Corn (Maize) - Northern Leaf Blight', 'Strawberry - Leaf Scorch', 'Tomato - Bacterial Spot', 'Peach - Bacterial Spot', 'Corn (Maize) - Common Rust', 'Strawberry - Healthy', 'Cherry - Healthy', 'Grape - Esca (Black Measles)', 'Apple - Cedar Apple Rust', 'Tomato - Yellow Leaf Curl Virus', 'Apple - Apple Scab', 'Apple - Black Rot', 'Corn (Maize) - Healthy', 'Peach - Healthy', 'Grape - Leaf Blight']\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ===============================\n# SECTION 2: Load Dataset & Apply Transformations\n# ===============================\n\n# Image transformations\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Load datasets\ntrain_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=train_transform)\nval_dataset   = torchvision.datasets.ImageFolder(root=val_dir, transform=val_transform)\n\n# Optional test dataset\nif os.path.exists(test_dir):\n    test_dataset = torchvision.datasets.ImageFolder(root=test_dir, transform=val_transform)\nelse:\n    test_dataset = None\n\n# Number of classes\nNUM_CLASSES = len(train_dataset.classes)\nprint(f\"Number of classes: {NUM_CLASSES}\")\nprint(\"Classes:\", train_dataset.classes)\n\n# DataLoaders\nBATCH_SIZE = 32\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\nif test_dataset:\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Validation samples: {len(val_dataset)}\")\nif test_dataset:\n    print(f\"Test samples: {len(test_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T06:31:40.508031Z","iopub.execute_input":"2026-02-13T06:31:40.508542Z","iopub.status.idle":"2026-02-13T06:31:52.333117Z","shell.execute_reply.started":"2026-02-13T06:31:40.508515Z","shell.execute_reply":"2026-02-13T06:31:52.332331Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 29\nClasses: ['Apple - Apple Scab', 'Apple - Black Rot', 'Apple - Cedar Apple Rust', 'Apple - Healthy', 'Bell Pepper - Bacterial Spot', 'Bell Pepper - Healthy', 'Cherry - Healthy', 'Cherry - Powdery Mildew', 'Corn (Maize) - Cercospora Leaf Spot', 'Corn (Maize) - Common Rust', 'Corn (Maize) - Healthy', 'Corn (Maize) - Northern Leaf Blight', 'Grape - Black Rot', 'Grape - Esca (Black Measles)', 'Grape - Healthy', 'Grape - Leaf Blight', 'Peach - Bacterial Spot', 'Peach - Healthy', 'Potato - Early Blight', 'Potato - Healthy', 'Potato - Late Blight', 'Strawberry - Healthy', 'Strawberry - Leaf Scorch', 'Tomato - Bacterial Spot', 'Tomato - Early Blight', 'Tomato - Healthy', 'Tomato - Late Blight', 'Tomato - Septoria Leaf Spot', 'Tomato - Yellow Leaf Curl Virus']\nTraining samples: 53693\nValidation samples: 12067\nTest samples: 1358\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ===============================\n# SECTION 3: Pre-trained ResNet18 & Federated Learning Setup\n# ===============================\n\n# Load pre-trained ResNet18\nimport torchvision.models as models\nglobal_model = models.resnet18(pretrained=True)\n\n# Replace final fully connected layer\nnum_ftrs = global_model.fc.in_features\nglobal_model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\nglobal_model = global_model.to(DEVICE)\nprint(global_model)\n\n# -------- Federated Averaging --------\ndef federated_average(global_model, local_models):\n    global_dict = global_model.state_dict()\n    for key in global_dict.keys():\n        global_dict[key] = torch.stack(\n            [local_models[i].state_dict()[key].float() for i in range(len(local_models))], 0\n        ).mean(0)\n    global_model.load_state_dict(global_dict)\n    return global_model\n\n# -------- Local Training Function --------\ndef train_local(model, train_dataset, epochs=3, batch_size=32, lr=0.0001):\n    model.train()\n    loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for images, labels in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(loader):.4f}\")\n    return model\n\n# -------- Evaluation Function --------\ndef evaluate(model, dataset, batch_size=32):\n    model.eval()\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return 100 * correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T06:32:08.105257Z","iopub.execute_input":"2026-02-13T06:32:08.105564Z","iopub.status.idle":"2026-02-13T06:32:08.737660Z","shell.execute_reply.started":"2026-02-13T06:32:08.105541Z","shell.execute_reply":"2026-02-13T06:32:08.737055Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44.7M/44.7M [00:00<00:00, 172MB/s] \n","output_type":"stream"},{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=29, bias=True)\n)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# ===============================\n# SECTION 4: Federated Learning Training Loop\n# ===============================\n\nNUM_CLIENTS = 2       # reduce for better per-client data\nLOCAL_EPOCHS = 3\nROUNDS = 2\nBATCH_SIZE = 32\nLR = 0.0001\n\n# Split dataset into clients (balanced)\ndef split_dataset(dataset, num_clients):\n    data_size = len(dataset)\n    indices = list(range(data_size))\n    random.shuffle(indices)\n    split_size = data_size // num_clients\n    client_datasets = []\n    for i in range(num_clients):\n        start = i * split_size\n        end = start + split_size if i < num_clients - 1 else data_size\n        client_datasets.append(Subset(dataset, indices[start:end]))\n    return client_datasets\n\nclient_datasets = split_dataset(train_dataset, NUM_CLIENTS)\nprint(f\"Dataset split into {NUM_CLIENTS} clients.\")\n\n# Federated Training\nglobal_model = models.resnet18(pretrained=True)\nglobal_model.fc = nn.Linear(global_model.fc.in_features, NUM_CLASSES)\nglobal_model = global_model.to(DEVICE)\n\nfor round_idx in range(ROUNDS):\n    print(f\"\\n--- Federated Round {round_idx+1}/{ROUNDS} ---\")\n    local_models = []\n\n    for client_idx in range(NUM_CLIENTS):\n        print(f\"Training client {client_idx+1}/{NUM_CLIENTS}\")\n        local_model = copy.deepcopy(global_model)\n        local_model = train_local(local_model, client_datasets[client_idx],\n                                  epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE, lr=LR)\n        local_models.append(local_model)\n\n    # Aggregate weights\n    global_model = federated_average(global_model, local_models)\n\n    # Evaluate global model on validation set\n    val_acc = evaluate(global_model, val_dataset, batch_size=BATCH_SIZE)\n    print(f\"Global Model Validation Accuracy after Round {round_idx+1}: {val_acc:.2f}%\")\n\nprint(\"\\n✅ Federated Training Complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T06:46:11.685904Z","iopub.execute_input":"2026-02-13T06:46:11.686709Z","iopub.status.idle":"2026-02-13T07:01:44.819489Z","shell.execute_reply.started":"2026-02-13T06:46:11.686674Z","shell.execute_reply":"2026-02-13T07:01:44.818655Z"}},"outputs":[{"name":"stdout","text":"Dataset split into 2 clients.\n\n--- Federated Round 1/2 ---\nTraining client 1/2\nEpoch 1/3 - Loss: 0.2483\nEpoch 2/3 - Loss: 0.0503\nEpoch 3/3 - Loss: 0.0304\nTraining client 2/2\nEpoch 1/3 - Loss: 0.2463\nEpoch 2/3 - Loss: 0.0458\nEpoch 3/3 - Loss: 0.0339\nGlobal Model Validation Accuracy after Round 1: 99.59%\n\n--- Federated Round 2/2 ---\nTraining client 1/2\nEpoch 1/3 - Loss: 0.0374\nEpoch 2/3 - Loss: 0.0214\nEpoch 3/3 - Loss: 0.0259\nTraining client 2/2\nEpoch 1/3 - Loss: 0.0369\nEpoch 2/3 - Loss: 0.0244\nEpoch 3/3 - Loss: 0.0224\nGlobal Model Validation Accuracy after Round 2: 99.68%\n\n✅ Federated Training Complete!\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# ===============================\n# SECTION 5: Test & Save Trained Global Model\n# ===============================\n\n# Evaluate on test dataset\nif test_dataset is not None:\n    global_model.eval()\n    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    correct = 0\n    total = 0\n    class_correct = [0] * NUM_CLASSES\n    class_total = [0] * NUM_CLASSES\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = global_model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            for i in range(len(labels)):\n                label = labels[i]\n                class_total[label] += 1\n                if predicted[i] == label:\n                    class_correct[label] += 1\n\n    overall_acc = 100 * correct / total\n    print(f\"\\nOverall Test Accuracy: {overall_acc:.2f}%\")\n    print(\"\\nPer-Class Accuracy:\")\n    for i, class_name in enumerate(test_dataset.classes):\n        if class_total[i] > 0:\n            acc = 100 * class_correct[i] / class_total[i]\n            print(f\"{class_name}: {acc:.2f}%\")\nelse:\n    print(\"No test dataset found. Skipping test evaluation.\")\n\n# Save global model\nMODEL_PATH = \"/kaggle/working/global_resnet_federated.pth\"\ntorch.save(global_model.state_dict(), MODEL_PATH)\nprint(f\"\\nGlobal model saved at: {MODEL_PATH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T07:01:52.685105Z","iopub.execute_input":"2026-02-13T07:01:52.685765Z","iopub.status.idle":"2026-02-13T07:01:58.607719Z","shell.execute_reply.started":"2026-02-13T07:01:52.685733Z","shell.execute_reply":"2026-02-13T07:01:58.607081Z"}},"outputs":[{"name":"stdout","text":"\nOverall Test Accuracy: 99.63%\n\nPer-Class Accuracy:\nApple - Apple Scab: 100.00%\nApple - Black Rot: 100.00%\nApple - Cedar Apple Rust: 100.00%\nApple - Healthy: 100.00%\nBell Pepper - Bacterial Spot: 100.00%\nBell Pepper - Healthy: 100.00%\nCherry - Healthy: 100.00%\nCherry - Powdery Mildew: 100.00%\nCorn (Maize) - Cercospora Leaf Spot: 95.56%\nCorn (Maize) - Common Rust: 100.00%\nCorn (Maize) - Healthy: 100.00%\nCorn (Maize) - Northern Leaf Blight: 97.92%\nGrape - Black Rot: 100.00%\nGrape - Esca (Black Measles): 100.00%\nGrape - Healthy: 100.00%\nGrape - Leaf Blight: 100.00%\nPeach - Bacterial Spot: 100.00%\nPeach - Healthy: 100.00%\nPotato - Early Blight: 100.00%\nPotato - Healthy: 100.00%\nPotato - Late Blight: 100.00%\nStrawberry - Healthy: 100.00%\nStrawberry - Leaf Scorch: 100.00%\nTomato - Bacterial Spot: 100.00%\nTomato - Early Blight: 100.00%\nTomato - Healthy: 100.00%\nTomato - Late Blight: 100.00%\nTomato - Septoria Leaf Spot: 100.00%\nTomato - Yellow Leaf Curl Virus: 95.92%\n\nGlobal model saved at: /kaggle/working/global_resnet_federated.pth\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# ===============================\n# SECTION 6: Single Image Inference\n# ===============================\n\nfrom PIL import Image\n\n# Load trained model\nloaded_model = models.resnet18(pretrained=False)\nloaded_model.fc = nn.Linear(loaded_model.fc.in_features, NUM_CLASSES)\nloaded_model.load_state_dict(torch.load(MODEL_PATH))\nloaded_model = loaded_model.to(DEVICE)\nloaded_model.eval()\nprint(\"Model loaded for inference.\")\n\n# Image transformation (must match training)\ninference_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\ndef predict_image(image_path):\n    \"\"\"\n    Predict crop disease for a single image\n    \"\"\"\n    img = Image.open(image_path).convert('RGB')\n    img_tensor = inference_transform(img).unsqueeze(0).to(DEVICE)  # add batch dimension\n    with torch.no_grad():\n        outputs = loaded_model(img_tensor)\n        _, predicted = torch.max(outputs.data, 1)\n    class_name = train_dataset.classes[predicted.item()]\n    return class_name\n\n# Example usage\ntest_image_path = \"/kaggle/input/datasets/snikhilrao/crop-disease-detection-dataset/Plant Village Dataset/Test/Apple - Apple Scab/03354abb-aa1c-4f9d-a1ef-9f40505cd539___FREC_Scab 3355.JPG\"  # replace with your image path\npredicted_class = predict_image(test_image_path)\nprint(f\"The predicted disease class is: {predicted_class}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T07:03:20.470625Z","iopub.execute_input":"2026-02-13T07:03:20.471481Z","iopub.status.idle":"2026-02-13T07:03:20.735522Z","shell.execute_reply.started":"2026-02-13T07:03:20.471451Z","shell.execute_reply":"2026-02-13T07:03:20.735023Z"}},"outputs":[{"name":"stdout","text":"Model loaded for inference.\nThe predicted disease class is: Apple - Apple Scab\n","output_type":"stream"}],"execution_count":42}]}